[Speaker 1]
Sit down, show me what's going on. Share it with us. So sir, I have started with generating the No, I have started with the manual chunking of the transcripts. I have to get all the transcripts from the video and then what I have done is I have read those transcripts and what I see the pattern was like I made the chunks accordingly like when you What was the goal? Goal was what? So goal was this that I will divide the transcripts in chunks and then what I will do, I will like to embed them So I will take those transcripts and embed them in a file like embedding I will do the embedding of the transcripts to chunks and then I will store them in a FIOS data structure. What FIOS data structure? You will do the So sir, it is like finding the similarities of the query and the transcript chunks or the cosine intervals Ok, fine. But that was for what purpose? Sir, to find the specific, like I have asked some question so I have embedded that question and then in the FIOS data structure, that question and the transcript chunk of that specific part will be matched and then I will give that transcript chunk to the LLM and he will explain accordingly This was what? This you have done? Ok, let's see how it goes Now there is another way of doing it You give the entire transcript to the LLM give the question and he will give some answer Sir, actually what was happening though I had given entire transcript to the LLM, it was translucent again It was like, I asked some question it was giving me some other answer It was happening so that's why I divided it into chunks So you have a baseline? This did not work? And this did work? And for how many meetings? Sir, only one How many meetings have I shared with you? Sir, you have shared me 6 meetings So whatever meetings I have shared you should have the baseline which is, I should give the entire transcript to the LLM and the asking question and give these problems you should document that Ok, then I will give him chunks Then you give chunks and you document because otherwise it's not scientific You have to say, I did this I tried it on 6 meetings, this happened then I tried this, this happened We need to be systematic in the process Ok, now show me what you have done this is for in the future, do it systematically so everything you try you record it, store it so that we can later on even that is something you are meeting transcript you should be able to say, you did this, this happened all that is results right now you are giving only transcript later you will also give results you will also give code you will also give everything 80 around Oxford whatever you are going to do for others that is the beginning your life will become easier so sir, first I have manually chunked them like when the topic was changing I read all the scripts so I chunked them accordingly then I have stored them in JSON file like every chunk in future I am thinking to automate this manually or automatically sir, but I was thinking when I automated this it was not like suddenly doing well because what was happening the topic changed and it was overlapping some topics but question is how much does that affect the final result even with those errors may be final result if I will give whole transcript so it can first tell me what have you done so what I have done is I have took a meeting so what I have done is I have took a meeting so what I have done is I have given user id to the specific chunk and meeting name and meeting time and I have given text in the specific chunk so I have done this for all the chunks then what I have done is generate ratings is like sir, I have called that bg model which was embedding the files this is chinese model yes sir use a better model they do but this bg model is not very good I have used it anyway, its ok this is part of demo you should find a model which has good paper on it and all that chinese model is used for demo so everybody uses it actually bg is not the best everybody uses it I know but its not the best model just because they have a demo people use it so sir what I have done is I have specifically created chunk embeddings so what is happening is like it was happening that meeting was crossing with each other so what I have done is I have created those meeting name and those were crossing each other so it was not happening afterwards then I have stored this is like storing embeddings what sir? sir what was happening like Agrim and Ashmit are two different persons so what was happening is like it was firstly hallucinating at Agrim's meeting and if I ask one question, it was giving his answer and if I ask so I have created those meeting id so these were the same embeddings then in that it was the chunk embeddings that happened this was just like cleaning for the cleaning purpose for the overlapping purpose like sir what I have done is in a specific chunk it is taking the last 30 words and it is like overlapping that in the next chunk so that if something is ending with specific so it can follow so you have overlapping things overlapping things so chunk embeddings on that so sir now I have two things like this was the first one thing, now what happened here is like it was creating the data structure, it was taking chunks it was taking chunks of the probably this chunk embeddings and it was taking the vectors now what happened here is I have removed all vectors of all specific chunks but the file data structure is only showing numbers so in future I will use that, right now I am not using that, what I will do in future is I will create different vectors for each user so that it will not overlapping afterwards you have to have some more metadata exactly, afterwards I will be using it but right now I am just storing those so in that now in generate answer now in this what I have done is first show it working

[Speaker 2]
so

[Speaker 1]
so so sir what tree chunks is doing is right now I have not used that vector index what it is doing is it is taking your user query and that it is creating in embeddings all user specific like I have taken one user I have taken user id of a user it is embedding that query and then from the stored transcripts that chunk embeddings I am not using vector index it is matching it is going in file data structure and then it is matching that user query embedding and stored chunk embedding then what's happening is ranking so I am ranking the most matched answers so you are doing a direct right now I am doing direct in the function right now in this video you are retrieving all of them and just storing them right now all the user specific what's happening is like if I have taken the user id of Ashmit so he will only retrieve Ashmit's embeddings and then you are just doing a comparison with all of them and finding the top top 1 or top 3 then you are giving that to the relevant so then supervisor agent supervisor agent is just the pipeline like I am taking that it has a function to find the nearest next you are finding the top 3 like that it does the ranking by itself it does the ranking by itself it does the matching by itself so then supervisor agent is just the pipeline that I just showed it is just taking the input and giving the output so let's take a random transcript I will take like which transcript is it sir this is my live meeting we can take some data like which was just ask some question about your meeting sir we can ask at what date was the next meeting I will connect this to the what is happening here why it is taking so long sir I think wifi wifi is here because of the meeting so sir I have entered the user ID Ashwin now it will be taking the embedding of those what I am doing in the session ID right now I will make memories I have not implemented a lambda but what I will do later is like I have asked some question like what was the date or what something so I will then ask the follow up question like explain me this question in specific detailed answer so it will take the previous question to the state to the state and then I will create that in next week this is random right now right so we can ask so it gave the answer it took the specific chance and it finds the ID and it gave the answer sir ask that the next meeting will be scheduled for next week what was the main action item for next meeting sir I will one again right now so what was the main action item discussed discussed and finalized we need to build a simple web based meeting agent that answer question for the meeting ok but what was the action item the immediate action item for the next week for the next week

[Speaker 2]
this is general

[Speaker 1]
which is correct for the immediate next week sir one more doubt that immediate deliverable immediate deliverable for the following for the following meeting for the following meeting but it is like the menu simple web based meeting to be integrated first option we agree that web based was the first one we agree on web based before next meeting yes sir you said web based and then i said web based is a problem and then i said command line command line why is it web based? because web based was planned who suggested web based meeting? web based was there in the paper in the paper first we put a slash and then in the end command line search you said a slash integration command line command line is written it is there but it is not retrieved in the chunk it is not retrieved in the chunk the immediate thing the point is this embedding retrieves the long chunk you have to devote this because this is a very important thing if the long chunk comes the answer will also be different what were you asking?

[Speaker 2]
sir i was asking can i normalize the transcripts

[Speaker 1]
like this transcript not this one

[Speaker 2]
this

[Speaker 1]
this is his transcript like this it was like hallucinating once can i normalize transcripts is there any model that can normalize transcripts this was some issue from the transcript this was a good one we told that we will put in the bit it can read full and then it can check the code accordingly this is yours someone came in between remember somebody came in there is somebody outside someone was standing outside sir but in video when i was listening to this transcript we were talking about something but that was not coming there was a noise sir i was asking is there any model that can normalize transcripts no you can go in Gemini and say get rid of stuff which appears to be noisy no no no so first i give transcripts to LLM then i store the transcripts so what is the action item now next time first of all i am thinking to automate that second one more thing so sir web based don't do web based it will take time keep it command line but keep it so that everything is properly in your own database and you can you log in to your chats it should tell you that meetings are coming for you both guys will be users each meeting will have all participants you log in all your meetings will be there and then you should be able to ask questions one by one by one and keep the context i ask one question same thing chat based but keep the context explain me the previous question then sometimes you have to go back from this context it may have to go and get one more chat right that's what you have to think clean it sometimes it has to get more chat sometimes it will just ask based on the current context it may need to go back and get one more meeting it is deciding what to do whether to go or not that decision is being made by two agents one is going to give the response other guy is going to decide to give more context ok either the previous answers or chunks previous answers and chunks do i need more information or not make it make it a proper system that i have so many things stored in the database i can retrieve based on the user id then keep asking questions and chat basically that thing should be the user the terminal layer should be very simple it should be something which you can take that backend piece and connect it to a slack bot also we will put slack bot in our meeting in our channel so backend we will host it and every time we will push have you made the repo? push it make me a collaborator and we will put a company also and they can also be a group they can also sit here let us get this working in a way for all our meetings yours, other guys whatever is there for these three groups where i am recording the meeting we are able to have on slack a conversation with the previous what is happening let us get a system working first by that time the company will wake up and they will provide their profit notes whatever they are recording we can use that ok sir the agreement the agreement now he is now able to pass the videos where is the demo what is the code that will also come in the transcript what did you show on the screen last time it will come clear any other question because if you have a question you better ask otherwise you will get lost close it sir so sir right now i was thinking that i have to create a system i have to implement a lambda that it can also answer the follow up questions and also i will be continuing this right now i am it should continue

[Speaker 2]
and

[Speaker 1]
it should also decide whether or not to get a new job so basically is he asking a different question which requires me to go back and get a new job or is it on the same context or do i need to go and get for that there will be a separate agent and sir that will be happening for a specific user yes for a specific user so sir in the command line i will first input the user id and then it will be continuing the transcript and other thing is the meeting that you get back you will have to get back for that user for that particular conversation right now it is for user only so we will do that later do it continuously once it is continuous then we will add help and slack that will be the first system and how is it going to be stored yes it is being stored in the file i am extending it along with every in the database there is the user id also there date everything is there meeting time yes meeting time and date will be there it is not just a vector you are also searching based on some other parameters so sir it will be storing that chat in a file for all questions and answers after the chat is off and this is chunk automation chunking automation understood then we will see how to deploy how to extend sure