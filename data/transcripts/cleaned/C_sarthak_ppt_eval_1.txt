[Speaker 2] I am an evaluator. I'll be evaluating your presentation based on the project and task requirements. Please begin when you're ready. Note, this session is being recorded.

[Speaker 1] Hello everyone, this is a project agent in AI. So it is an AI chatbot application that simulates the patient behavior, which interacts with a user who is acting as a doctor. The message sent by the user goes to the backend through FastAPI, which acts like a bridge between the frontend and the backend. Then the message goes to the land graph, where it is classified. This intent classification helps the land chain to create a response accordingly. We also maintain patient memory so that the bot does not forget the context of the conversation. The tasks performed by the land graph, land chain, and patient memory together are known as the agent, which is created for a particular session ID. Tasks are completed with the help of an LLM accessed via API key. The reply generated by the agent goes back to the frontend through FastAPI. Technology used. The frontend is deployed on Vercel. The backend is deployed on Render. The Identity AI is built with LangChain and LangGraph. The LLM is served via Grok for fast response generation. The backend is coded in Python and the frontend is built using HTML, CSS and JavaScript. Key design choices. The message which goes to the LangGraph can be classified as an intake message, a treatment message or a closing message. Once a message is classified as closing, a conversation-ended flag becomes true, and any further input receives a session-ended response. A new session ID can be created using the reset button.

[Speaker 2] You mentioned that the message goes to the LangGraph where it is classified. Could you elaborate on how this LangGraph is implemented and what features of the message it uses for intent classification?

[Speaker 1] I would like to show you the code for intent classification. We use an LLM here, which is Grok, accessed through the API key. We set the temperature to zero so that we get deterministic output. In the prompt, we define rules based on key terms. For example, intake when the user says hi or hello, treatment when treatment is recommended, and closing when the user politely ends the conversation. The message is classified and a JSON value is returned by the LLM indicating whether the message is intake, treatment, or closing.

[Speaker 2] You mentioned setting the temperature to zero. Could you elaborate on why you chose this specific value and what effect it has?

[Speaker 1] Temperature zero ensures deterministic output. Since intent classification only determines user intent, randomness is undesirable. This helps LangChain generate clearer responses based on intent.

[Speaker 2] I'm following your presentation. Please continue.

[Speaker 1] Here is another demonstration of chatbot functionality. The session ID created on the frontend goes to the backend with the user message. If that user ID already has an agent, the same agent is reused; otherwise, a new agent is created.

[Speaker 2] You mentioned that the same agent is reused. Can you elaborate on how you ensure the correct agent state is maintained?

[Speaker 1] We maintain a dictionary that stores session IDs as keys and agent objects as values. When a request comes, the dictionary is checked. If the session ID exists, the same agent is used, ensuring isolation between sessions.

[Speaker 2] You mentioned that the object stored is the agent created for each session ID. Could you elaborate on how this agent object is structured?

[Speaker 1] The agent object is created using a create_agent function, which invokes the LangGraph. The agent is activated and replies are generated through it.

[Speaker 2] You mentioned that the agent is basically a patient which contains a LangGraph. Could you elaborate?

[Speaker 1] The LangGraph maintains the control flow. It classifies intent so that LangChain can generate responses based on intent. The graph structure ensures the flow between intake, treatment, and closing states.

[Speaker 2] I'm following your presentation. Please continue. So here is a demonstration of our application.

[Speaker 1] I can start the conversation by asking about symptoms. The bot responds accordingly. I can ask follow-up questions, and responses are generated based on context. The session ID is created after the first message and reused for subsequent messages. I can give treatment intent, accept treatment, and then end the conversation. Once the conversation ends, further messages return a consultation-ended response.

[Speaker 2] Evaluation has been successfully saved. You may now disconnect.