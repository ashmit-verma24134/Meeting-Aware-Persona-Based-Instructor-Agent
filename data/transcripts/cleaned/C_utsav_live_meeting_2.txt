[Speaker 1]
I've shared a couple of links with you just now. First, there's this paper, Generative Agents, right? You've seen that, right? So what they did is they put lots of relevant agents in a word and let them walk around and do things and make things happen, right? Read it carefully, how they've done that. You read it? The second one is this one, which you know about text-based games, right? Adventure games and Zork and stuff like that, right? So this put LLM inside those games and said, can you play them? So read this paper, right? And this paper has a link to their code, which is not, I've just tried to get it unlocked from the IIIT network, but it's right now some blockages there, so I'm telling you on my phone, right? I said this is not a game site, this is actually a research paper site, right? So just because it's called .ai or something, it's, but basically they have various games and they have the code for that, et cetera. This uses an environment called Jericho, right? Which allows basically, if you look at the quick start, you basically can, you have to do all this stuff and then you get the games, right? And then you basically create the environment, right? So you have to get this Z5 environment from whatever this Jericho game suite, right? You have to put this somewhere and you do, right? And you just see if you can use this. Basically, this lets you play the game in Python. So this TextQuest actually uses this environment to do play games, right? So what we want to do is first, all these games are single user games, right? So I'll start with that, that single user games are a problem. But first goal is let's get an LLM agent to play a game, right? The game environment will have a description of what's happening, et cetera, et cetera, right? And what we need to do is once the LLM agent goes and plays the game and maybe you should make it talks to itself, maybe it talks to somebody else, et cetera, et cetera. So let's say it plays the game, one. Second, let's see. There's this. I basically generated, I used the VO3 video generator of Google, right? So you basically, you have to create it. So we'll come to the keys issue later, right? So you have first person view of talking to a customer and trying to sell them a washing machine, right? Or other case, I had various different. So basically, we generated some videos like this, right?

[Speaker 2]
So this is a great deal.

[Speaker 1]
So it generates a video. It's pretty costly, right? So each of these things will probably end up eight seconds But you have, have you created an account in Germany?

[Speaker 2]
Are you exhausted?

[Speaker 1]
Are you exhausted 300 credits? When did you create? Last month. You still have some time. You have those 300 credits free, right? For example, I have over here my Germany account. If you associate a billing, look at the credits. So when you create an account and make it a paid account, right? You get 26,000 rupees. It lasts for three months, but that's okay. Enough for this course, right? So you have two months of your account left, right? And then you can use my account after that, right? So I hope you won't exhaust, but your time will exhaust. But then after that, you can use mine, right? So you can be pretty, 26,000 means pretty much like 2,000 videos, right? Isn't it? No. 200 videos, right? Those four videos are occurring, right? So 200 videos, I mean, each second may cost you 100 rupees to make a video or something, right? That's what, for eight seconds, right? So it depends, right? You can see. But don't be too free about making videos, okay? Now there's a 1,000 rupee joining fee to pay. You can get, I'll write a note. You can get it back from there. And even if it goes above this, whatever it is, you can get back from there. But don't spend too much on the videos, okay?

[Speaker 1]
So the idea is this. First goal, use the Jericho environment, study those papers, how they made the LLMs, do various things, etc. Now the LLM is not just doing it blindly, right? So some of the ideas of the Simulca paper, you'll have to start thinking how to do, right? You'll keep the memory, what it's doing on, etc., etc., right? And so for the first goal, I think in January, we should get the situation where for one or two or three games, you can play a game. And then for any particular part of that game, we can generate a small video, right? So the game has all of the transcript. I did this, I did this, I saw this, I saw this. And then you generate a video of the player playing that game as if he's going there. So it's like you're creating that clip, right? And then that's step one, right? Hopefully this month we can do that, right? So just one clip for one eight-second period. Then there may be multiple clips. This concept of having continuity, having the same look and feel throughout the game, all that can be done, but we won't do that now. So that requires taking the first image and last image and making sure you give those two images and the video will interpolate between them. So it looks like the same environment you're playing through, right? That is the part two, right? But after first month, part two ke pehle, what we want to do is we want to, that you can start, once you start understanding this environment, you start understanding how to make a non-playing character in this environment, right? Or something in this environment, which is, can speak or do something like using an agent, right? Rather than the agent only taking actions and just creating a video with hardly any articulation, maybe music or whatever. There is somebody who's speaking back, right? Some animal says something, some, whatever, these are various types, right? So how do you bring a non-player character into this environment that you do some R&D on, right? You do that while you're doing this basic work, right? And then the step two will be that now you have non-player characters who are LLM agents, right? They are speaking, you are going, you are speaking to them as an agent, right? So you are articulating something to them, which is going into the, some is going into the game. Some is going into your transcript of the game. Means what I speak normally doesn't go to the game. Game doesn't care what you speak. Game only cares did you go right, left, did you pick up the sword, did you do this, did you do that, right? It doesn't care what you said. But you keep that speech here. What that guy said, once you have made changes to this, so that there's a non-player character who can speak, not just take action. Then their speech will come through the game and come back to us or come sideways somehow, some channel you have to make, right? And that becomes part of the transcript. Next time you have video in part two, you will have not only just the environment, but you will also have other players talking to you in that game. And that is what gets animated. So it becomes like a mini story. So that's the basic thing. And if you can get that far, it would be very nice. Then we can see if there's time we can try to stitch the videos together to make them continual. And then, of course, if we get even that far, I don't think we will in one semester. But suppose now you want to put your avatar into the game. That means you will register your face and your personality and say, now you will speak with my personality. That's just prompts, right? Prompts and that's all bells and whistles. This can be done later. Right. OK. A core engine has to be built. No UI, no UI.

[Speaker 1]
Let's just if I just add the code level, let's build this. Then we can make we can think about making that later. Right. If you want to do it in some other time or whatever else you want, somebody else will do it. Is it clear? Tell me now what you expect to do in the project and what you expect to do.

[Speaker 2]
So one thing I want to say is that I read the generated engine paper and I tried to build something like that. So from Python, what I will do is, let's say we build a 2D world. We will be adding rooms of cuboid shape or multiple cuboid shapes to make one room. And in those rooms we can add multiple agents that will be interacting with each other and talking to each other. So for that in Python, I coded a message queue, like message bus, that if one agent wants to send a message, it will send to this message bus. It will be thing based, like every agent should take some action or process what message they have received, read the inbox.

[Speaker 1]
So you already have the core elements of a multi-agent thing, but you have to stitch it into this. Why? Because these games already have some descriptions of castles or... Oh, who wrote the descriptions? Already have, because all the games are built in. Let's just use that, because somebody has written it.