{
  "user_id": "ashmit",
  "meeting_name": "auto_session",
  "session_start_time": "2026-01-19T00:57:20.208279",
  "session_end_time": "2026-01-19T01:00:59.328797",
  "conversation": [
    {
      "question": "Why was manual chunking introduced?",
      "answer": "Manual chunking was added to split the full transcript into smaller, overlapping pieces so that each chunk could be embedded and matched against user queries. This was needed because feeding the entire transcript to the LLM produced irrelevant or \u201challucinated\u201d answers. Chunking therefore improves the accuracy of similarity\u2011based retrieval.",
      "timestamp": "2026-01-19T00:57:54.481696"
    },
    {
      "question": "what type of irrelevant or hallucinated answers",
      "answer": "The hallucinated answers were those where the model returned information from the wrong meeting or participant\u2014e. g. , it would answer a question about Ashmit\u2019s meeting with content from Agrim\u2019s meeting.",
      "timestamp": "2026-01-19T00:58:44.550042"
    }
  ]
}